{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lib库解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先导个库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理操作基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n           = 12 #用来做下文数据代指的\n",
    "tensor_hang = 3  #用来进行行指代\n",
    "tensor_lie  = 4  #用来进行列指代\n",
    "tensor_zong = 2  #用来进行纵指代"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_operator_basic = tor.arange(n)\n",
    "x_data_operator_basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数名字：arange(n)\n",
    "- 函数作用：是填入数据n生成一个从0~n-1的张量\n",
    "- 函数输入：数字 n\n",
    "- 函数输出：torch的张量（1 x n）\n",
    "- 函数依赖：否"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_operator_basic.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数名字：numel()\n",
    "- 函数作用：输出torch_tensor含有的所有元素的总数\n",
    "- 函数输入：无（依赖型）\n",
    "- 函数输出：标量数字\n",
    "- 函数依赖：是--依赖torch_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_operator_basic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数名字：shape\n",
    "- 函数作用：输出torch_tensor的结构\n",
    "- 函数输入：无（依赖型）\n",
    "- 函数输出：torch.size()【这是一个会描述torch_tensor结构的数据类型】\n",
    "- 函数依赖：是--依赖torch_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_operator_basic.reshape(tensor_hang,tensor_lie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数名字：reshape(行,列)\n",
    "- 函数作用：将torch_tensor在元素不变的情况下结构发生改变，变为 n行 m列\n",
    "- 函数输入：tensor_hang 要改变成的张量的行 tensor_lie 要改变成的张量的列\n",
    "- 函数输出：变化后的张量\n",
    "- 函数依赖：是--依赖torch_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tor.zeros((tensor_zong,tensor_hang,tensor_lie))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数名字：zeros((张量结构))\n",
    "- 函数作用：生成全零的张量\n",
    "- 函数输入：张量的结构\n",
    "- 函数输出：全零的特定结构的torch_tensor\n",
    "- 函数依赖：否"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tor.ones((tensor_zong,tensor_hang,tensor_lie))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数名字：ones((张量结构))\n",
    "- 函数作用：生成全1的张量\n",
    "- 函数输入：张量的结构\n",
    "- 函数输出：全1的特定结构的torch_tensor\n",
    "- 函数依赖：否"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7816, -0.0295, -0.6303, -0.8054],\n",
       "         [-0.9329,  0.9743,  0.4026, -1.5266],\n",
       "         [ 2.0828, -0.0584, -0.9778,  0.7083]],\n",
       "\n",
       "        [[-0.5941,  0.2936, -1.1415,  1.0712],\n",
       "         [ 0.4574, -0.0423,  0.2291, -1.3703],\n",
       "         [-0.6084,  0.5535,  1.6587,  0.4079]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tor.randn((tensor_zong,tensor_hang,tensor_lie))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数名字：randn((张量结构))\n",
    "- 函数作用：生成全任意数<0~1>的张量\n",
    "- 函数输入：张量的结构\n",
    "- 函数输出：全任意数<0~1>的特定结构的torch_tensor\n",
    "- 函数依赖：否"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 4, 3],\n",
       "        [1, 2, 3, 4],\n",
       "        [4, 3, 2, 1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tor.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数名字：tensor([张量详细结构及数据])  【数据书写方式为一个方括号为一层，方括号中只能填写元素或包裹其他方括号，方括号中若为元素，表示的是列元素。如果是行的话就是逗号分隔两个内含元素的方括号；如果是纵的话就是逗号分隔两个是行的方括号；以此类推】\n",
    "- 函数作用：生成你自己设计的torch_tensor\n",
    "- 函数输入：自己设计的张量的结构和数据\n",
    "- 函数输出：自己设计的特定结构的torch_tensor\n",
    "- 函数依赖：否"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(11), tensor([1]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_operator_basic[-1],x_data_operator_basic[1 : 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 这是一个python的基础使用 -1 是倒数第一个**这一层的元素**（可能不是直接是数字哦）\n",
    "> \n",
    "> 分号是这个区间内的**这一层的元素**1:2是只有1，大的那个不会出现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0, 100,  12,  12,  12,   5, 100,   7,   8,   9,  10,  11])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_operator_basic[1] = 19\n",
    "x_data_operator_basic[2 : 5] = 12\n",
    "x_data_operator_basic[1 : 11 : 5] = 100\n",
    "x_data_operator_basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 这是一个元素修改的问题\n",
    "> \n",
    "> 其实就是逗号就是分层（维度）\n",
    ">\n",
    "> 其实分号就是本层区块操作\n",
    ">\n",
    "> (hang_head):(hang_tail):step 双分号后面那个就是每隔多少一读"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00,        inf, 1.6275e+05, 1.6275e+05, 1.6275e+05, 1.4841e+02,\n",
       "               inf, 1.0966e+03, 2.9810e+03, 8.1031e+03, 2.2026e+04, 5.9874e+04])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tor.exp(x_data_operator_basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数名字：exp(torch_tensor)\n",
    "- 函数作用：生成一个与输入的torch_tensor一样结构的张量，但是张量里的数字全变为指数项\n",
    "- 函数输入：torch_tensor\n",
    "- 函数输出：$e^{torch\\_tensor}$当然这也是一个张量\n",
    "- 函数依赖：否"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3.,  4.,  6., 10.]),\n",
       " tensor([-1.,  0.,  2.,  6.]),\n",
       " tensor([ 2.,  4.,  8., 16.]),\n",
       " tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n",
       " tensor([ 1.,  4., 16., 64.]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tor.tensor([1.0, 2, 4, 8])\n",
    "y = tor.tensor([2, 2, 2, 2])\n",
    "x + y, x - y, x * y, x / y, x ** y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|元素级运算符|解释|\n",
    "|--|--|\n",
    "| **+** | 元素相加 |\n",
    "| **-** | 元素相减 |\n",
    "| **\\*** | 元素相乘 |\n",
    "| **/** | 元素相除 |\n",
    "| **\\*\\*** | 元素指数操作 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 2.,  1.,  4.,  3.],\n",
       "         [ 1.,  2.,  3.,  4.],\n",
       "         [ 4.,  3.,  2.,  1.],\n",
       "         [ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.,  0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.,  4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.,  8.,  9., 10., 11.]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tor.arange(12, dtype=tor.float32).reshape((3,4))\n",
    "Y = tor.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "Z = tor.arange(12, dtype=tor.float32).reshape((3,4))\n",
    "tor.cat((X, Y, Z), dim=0), tor.cat((X, Y, Z), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数名字：cat((torch_tensor1, torch_tensor2, torch_tensor3……), dim = 层数)\n",
    "- 函数作用：将输入的torch_tensor依据编写的dim层数数据在相应层次上拼接\n",
    "- 函数输入：(torch_tensor1,torxh_tensor2……), dim = n\n",
    "- 函数输出：拼接好的torch_tensor\n",
    "- 函数依赖：否"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 小提示\n",
    ">\n",
    "> arange 可以依据 dtype参数的强制修改进行数据格式的强制修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X == Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是依据相等符进行张量兵对兵将对将的二元比较形成一个新的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(286)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_operator_basic.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数名字：sum()\n",
    "- 函数作用：将依赖的torch_tensor进行数值求和\n",
    "- 函数输入：无\n",
    "- 函数输出：所有元素的求和\n",
    "- 函数依赖：是--依赖torch_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编程错误注意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tor.arange(3).reshape((3, 1))\n",
    "b = tor.arange(2).reshape((1, 2))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l-zh-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
