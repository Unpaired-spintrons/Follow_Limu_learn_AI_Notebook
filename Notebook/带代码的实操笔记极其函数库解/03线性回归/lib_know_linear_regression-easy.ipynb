{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lib库解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as tor\n",
    "from torch.utils import data as tor_u_data\n",
    "from d2l import torch as d2l_tor\n",
    "from torch import nn as tor_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导个库先"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### synthetic(weight, bias, 数据量)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 2]), torch.Size([1000, 1]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight  = tor.tensor([2, 3.4])\n",
    "bias    = 5\n",
    "\n",
    "featrues, labels = d2l_tor.synthetic_data(weight, bias, 1000)\n",
    "featrues.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数名称：synthetic\n",
    "- 函数作用：用于仿真数据\n",
    "- 函数输入：weight【系数项，要有X的】 bias【常数项】 number【生成数据的数量】\n",
    "- 函数输出：featrues【生成的X】，labels【生成的y值】\n",
    "- 函数依赖：无"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from torch.utils import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个里面有许多都是关于数据处理的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorDataset(*(数据变量名列表))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tor_u_data.TensorDataset(*(featrues, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数名称：TensorDataset\n",
    "- 函数作用：将数据转化为torch.utils 的 data类中可操作的张量数据\n",
    "- 函数输入：*(数据列表) 【数据列表含有所有的array组（多个array）】\n",
    "- 函数输出：转化成功的torch.utils 的 data 类的数据\n",
    "- 函数依赖：无"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10 # 池化的单池内数据数量\n",
    "\n",
    "data_batch = tor_u_data.DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数名称：DataLoader\n",
    "- 函数作用：用于对数据进行池化装载(池化就是数据切小段)\n",
    "- 函数输入：dataset 数据集(被转化过) batch_size 池化单池数据量 shuffle 是否洗牌(打乱顺序)属性\n",
    "- 函数输出：池化后的的数据块(返回的是地址)\n",
    "- 函数依赖：无"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，这是一个专门用于 **n**erual **n**etwork 的库，里面有各种模型和一些方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential(模型组合表(前后))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = tor_nn.Sequential(tor_nn.Linear(2,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数名称：Sequential\n",
    "- 函数作用：存放模型的容器，在这里面放一张表，表就是机器学习执行的顺序\n",
    "- 函数输入：模型表\n",
    "- 函数输出：一个网络\n",
    "- 函数依赖：无"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数名称：Linear\n",
    "- 函数作用：创建一个线性模型\n",
    "- 函数输入：输入的数据列数，输出数据需要的页数\n",
    "- 函数输出：网络\n",
    "- 函数依赖：无"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weight与bias元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.fill_(0)\n",
    "net[0].bias.data.fill_(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **weight**\n",
    "weight是net中的一个成员元素，是用于作为系数的，其中它还有一个成员叫data，这就十分的显而易见了，就是数据，之后操作方式依照python一贯的套娃就好了，操作方式就像tensor样\n",
    "##### **bias**\n",
    "就是常数，其余同上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tor_nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数名称：MSELoss\n",
    "- 函数作用：创建 $L_2$ 范数(平方范数)的随时函数计算方法\n",
    "- 函数输入：无\n",
    "- 函数输出：网络(计算可以照着对象输出)\n",
    "- 函数依赖：无"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optim.SGD(parameter(), learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = tor.optim.SGD(net.parameters(), lr=0.03) # optim 就是optimizer 优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数名称：optim.SGD\n",
    "- 函数作用：创建随机梯度下降的优化方法\n",
    "- 函数输入：parameter()【net，由tor_nn模块搞的网络模型】 learn_rate 学习率\n",
    "- 函数输出：创建的优化器(与模型网络绑定)\n",
    "- 函数依赖：无"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数名称：.step()\n",
    "- 函数作用：优化器执行一步\n",
    "- 函数输入：无\n",
    "- 函数输出：无(但优化的数据已经自动跟新到了net中)\n",
    "- 函数依赖：torch.optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数名称：.zero_grad()\n",
    "- 函数作用：优化器梯度清零(防止累加，torch不会自动清零)\n",
    "- 函数输入：无\n",
    "- 函数输出：无(但优化的数据已经自动跟新到了net中)\n",
    "- 函数依赖：torch.optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原生Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### next && iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 4.8602e-01, -1.0630e+00],\n",
       "         [-4.8836e-01,  1.9515e-01],\n",
       "         [-1.9996e+00, -5.6600e-01],\n",
       "         [-1.1154e-01, -1.2552e-03],\n",
       "         [-2.1708e-01, -5.8709e-03],\n",
       "         [ 1.2893e+00,  5.3370e-01],\n",
       "         [ 8.1679e-01, -1.4658e-01],\n",
       "         [ 9.2891e-01,  1.8506e+00],\n",
       "         [ 5.2304e-01,  4.7185e-01],\n",
       "         [ 1.6753e+00,  3.5857e-01]]),\n",
       " tensor([[ 2.3626],\n",
       "         [ 4.6845],\n",
       "         [-0.9200],\n",
       "         [ 4.7597],\n",
       "         [ 4.5520],\n",
       "         [ 9.3836],\n",
       "         [ 6.1381],\n",
       "         [13.1415],\n",
       "         [ 7.6403],\n",
       "         [ 9.5652]])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_array(data_arrays, batch_size, is_train = True):\n",
    "    \"\"\"构造一个PyTorch数据迭代器\"\"\"\n",
    "    dataset = tor_u_data.TensorDataset(*data_arrays)                    # 将数据据转化为适合torch.utils.data进行操作的类型\n",
    "    return tor_u_data.DataLoader(dataset, batch_size, shuffle=is_train) # 是一个装载器，其实就是进行之前那个洗牌操作，搞池化的操作\n",
    "\n",
    "batch_size = 10\n",
    "data_iter = load_array((featrues, labels), batch_size)\n",
    "\n",
    "next(iter(data_iter))                                                   # next是返回下一个迭代对象，而iter是生成迭代对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数名称：next()\n",
    "- 函数作用：返回在带有迭代的元素的的输入的，返回下一个迭代对象\n",
    "- 函数输入：带有迭代的数据\n",
    "- 函数输出：下一个迭代的数据\n",
    "- 函数依赖：带有迭代的玩意"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 函数名称：iter()\n",
    "- 函数作用：用于产生迭代结果\n",
    "- 函数输入：带有迭代的数据\n",
    "- 函数输出：迭代的数据当前的数值\n",
    "- 函数依赖：带有迭代能力的变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实操详情"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[实操详情请见实操笔记](operator_linear_regression-easy.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l-zh-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
